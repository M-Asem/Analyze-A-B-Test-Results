{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists.  It is important that you get some practice working with the difficulties of these \n",
    "\n",
    "For this project, you will be working to understand the results of an A/B test run by an e-commerce website.  Your goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we setup\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Now, read in the `ab_data.csv` data. Store it in `df`.  **Use your dataframe to answer the questions in Quiz 1 of the classroom.**\n",
    "\n",
    "a. Read in the dataset and take a look at the top few rows here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ab_data.csv')  #Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use the below cell to find the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       294478 non-null  int64 \n",
      " 1   timestamp     294478 non-null  object\n",
      " 2   group         294478 non-null  object\n",
      " 3   landing_page  294478 non-null  object\n",
      " 4   converted     294478 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() #To get a glimpse of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294473</th>\n",
       "      <td>751197</td>\n",
       "      <td>2017-01-03 22:28:38.630509</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294474</th>\n",
       "      <td>945152</td>\n",
       "      <td>2017-01-12 00:51:57.078372</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294475</th>\n",
       "      <td>734608</td>\n",
       "      <td>2017-01-22 11:45:03.439544</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294476</th>\n",
       "      <td>697314</td>\n",
       "      <td>2017-01-15 01:20:28.957438</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294477</th>\n",
       "      <td>715931</td>\n",
       "      <td>2017-01-16 12:40:24.467417</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290584 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                   timestamp      group landing_page  converted\n",
       "0        851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1        804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2        661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3        853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4        864975  2017-01-21 01:52:26.210827    control     old_page          1\n",
       "...         ...                         ...        ...          ...        ...\n",
       "294473   751197  2017-01-03 22:28:38.630509    control     old_page          0\n",
       "294474   945152  2017-01-12 00:51:57.078372    control     old_page          0\n",
       "294475   734608  2017-01-22 11:45:03.439544    control     old_page          0\n",
       "294476   697314  2017-01-15 01:20:28.957438    control     old_page          0\n",
       "294477   715931  2017-01-16 12:40:24.467417  treatment     new_page          0\n",
       "\n",
       "[290584 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset = [\"user_id\"])\n",
    "#Getting the number of unique users by dropping the duplicates and finding the number of rows which equals 290584"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['converted'] == 1).mean() \n",
    "#The best way to get the proportion is by using the mean function to calculate the number of conversion/total number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    290585\n",
       "True       3893\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.query('landing_page == \"new_page\"')['group'] == 'control').value_counts() + (df.query('landing_page == \"old_page\"')['group'] == 'treatment').value_counts()\n",
    "#The ordinary thing is that new page lines up with treatment and old page with control so we used the opposite conditions with value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()[0]\n",
    "#It was obvious from the info() function that we used earlier there were no null values and we made sure by using isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows where **treatment** is not aligned with **new_page** or **control** is not aligned with **old_page**, we cannot be sure if this row truly received the new or old page.  Use **Quiz 2** in the classroom to provide how we should handle these rows.  \n",
    "\n",
    "a. Now use the answer to the quiz to create a new dataset that meets the specifications from the quiz.  Store your new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.query(\"group == 'treatment' and landing_page == 'old_page'\").index, inplace=True)  \n",
    "df.drop(df.query(\"group == 'control' and landing_page == 'new_page'\").index, inplace=True)\n",
    "df.to_csv('new_dataset.csv', index=False)\n",
    "#Dropping the values in which the new_page and treatment don't line up and storing it to a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290585 entries, 0 to 290584\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       290585 non-null  int64 \n",
      " 1   timestamp     290585 non-null  object\n",
      " 2   group         290585 non-null  object\n",
      " 3   landing_page  290585 non-null  object\n",
      " 4   converted     290585 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('new_dataset.csv')\n",
    "df2.info()\n",
    "#Reading the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145311"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['landing_page'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use **df2** and the cells below to answer questions for **Quiz3** in the classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. How many unique **user_id**s are in **df2**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"user_id\"].value_counts().count()\n",
    "#value_counts() for finding the unique values and count() for finding the total number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b. There is one **user_id** repeated in **df2**.  What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773192    2\n",
       "630732    1\n",
       "811737    1\n",
       "797392    1\n",
       "795345    1\n",
       "         ..\n",
       "650647    1\n",
       "648598    1\n",
       "654741    1\n",
       "652692    1\n",
       "630836    1\n",
       "Name: user_id, Length: 290584, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"user_id\"].value_counts()\n",
    "#value_counts() for displaying the unique users and it's obvious that we have a duplicated user_id which is \"773192\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is the row information for the repeat **user_id**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1876   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2862   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['user_id'] == 773192]\n",
    "# Same user has logged on to the website twice as we can see from the different timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Remove **one** of the rows with a duplicate **user_id**, but keep your dataframe as **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop_duplicates(inplace = True)\n",
    "#Dropping one of the iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use **df2** in the below cells to answer the quiz questions related to **Quiz 4** in the classroom.\n",
    "\n",
    "a. What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959667567149027"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df2.loc[df2['converted'] == 1].count()/df2['converted'].count())[0]\n",
    "#Finding the probability by dividing the number of conversions / total number of conversions and non conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df2.query('group == \"control\"')['converted'] == 1).mean()\n",
    "#Finding the probability in case of control group by using mean() function instead of counting and dividing by the total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880724790277405"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df2.query('group == \"treatment\"')['converted'] == 1).mean()\n",
    "#Finding the probability in case of treatment group by using mean() function instead of counting and dividing by the total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000636646764286"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df2.loc[df2['landing_page'] == \"new_page\"].count()/df2['landing_page'].count())[0]\n",
    "#Finding the probability by dividing the number of new pages / total number of landing pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Consider your results from a. through d. above, and explain below whether you think there is sufficient evidence to say that the new treatment page leads to more conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From question d, it is very obvious that the probability of receiving the new page is approximately 0.5 which means that the probability of receiving the old page is 0.5 too and the experiment is not biased at all in other wards the number of receiving old page is equal to the number of receiving the new page, and when we look at questions c and b we can conclude that the probability of converting the control group which is aligned with the old page is approximately 12.04% while the probability of converting the treatment group which is aligned with the new page is roughly 11.88% so the new treatment doesn't lead to more conversions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Notice that because of the time stamp associated with each event, you could technically run a hypothesis test continuously as each observation was observed.  \n",
    "\n",
    "However, then the hard question is do you stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do you run to render a decision that neither page is better than another?  \n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "\n",
    "`1.` For now, consider you need to make the decision just based on all the data provided.  If you want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, what should your null and alternative hypotheses be?  You can state your hypothesis in terms of words or in terms of **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                     H0: P new - P old <= 0\n",
    "                                     H1: P new - P old > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "Use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "Perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>\n",
    "\n",
    "Use the cells below to provide the necessary parts of this simulation.  If this doesn't make complete sense right now, don't worry - you are going to work through the problems below to complete this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What is the **convert rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959667567149027"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_new = df2.converted.mean()\n",
    "P_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the **convert rate** for $p_{old}$ under the null? <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959667567149027"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_old = df2.converted.mean()\n",
    "P_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145311"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new = (df2.query('group == \"treatment\"')).count()[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old = (df2.query('group == \"control\"')).count()[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_page_converted = np.random.binomial(1, P_new, n_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_page_converted = np.random.binomial(1, P_old, n_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0023293155916593866"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.mean() - old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Simulate 10,000 $p_{new}$ - $p_{old}$ values using this same process similarly to the one you calculated in parts **a. through g.** above.  Store all 10,000 values in a numpy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00145604,  0.0013049 , -0.00088367, ..., -0.00098708,\n",
       "       -0.00047107, -0.0009664 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_diffs = [] #An array for filling it with the difference between converted new and old pages\n",
    "\n",
    "new_page_converted = np.random.binomial(n_new,P_ùëõùëíùë§,10000)/n_new\n",
    "old_page_converted = np.random.binomial(n_old,P_old,10000)/n_old\n",
    "p_diffs = new_page_converted - old_page_converted \n",
    "p_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs**.  Does this plot look like what you expected?  Use the matching problem in the classroom to assure you fully understand what was computed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_diff = df2[df2.group == 'treatment'].converted.mean() - df2[df2.group == 'control'].converted.mean()\n",
    "\n",
    "plt.hist(p_diffs);\n",
    "plt.axvline(obs_diff, color='r'); #For plotting the observed difference in red colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9054"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_diffs >= obs_diff).mean()\n",
    "#p-value approximately equals 1 so we fail to reject the null hypothesis and it means that the new page has no effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. In words, explain what you just computed in part **j.**  What is this value called in scientific studies?  What does this value mean in terms of whether or not there is a difference between the new and old pages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's called p-value and it indicates the probability of observing our statistic or a more extreme statistic from the null hypothesis. For example if p-value equals 1 then we fail to reject the null hypothesis and when it equals 0 we can reject the null hypthesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. Fill in the below to calculate the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old = (df2.query('group == \"control\"')['converted'] == 1).sum()\n",
    "convert_new = (df2.query('group == \"treatment\"')['converted'] == 1).sum()\n",
    "n_old = (df2.query('group == \"control\"')).count()[0]\n",
    "n_new = (df2.query('group == \"treatment\"')).count()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now use `stats.proportions_ztest` to compute your test statistic and p-value.  [Here](http://knowledgetack.com/python/statsmodels/proportions_ztest/) is a helpful link on using the built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3116075339133115, 0.905173705140591)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score, p_value = sm.stats.proportions_ztest([convert_new, convert_old], [n_new, n_old], alternative='larger')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. What do the z-score and p-value you computed in the previous question mean for the conversion rates of the old and new pages?  Do they agree with the findings in parts **j.** and **k.**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Z-score is the standard deviation from the mean and p-value and it indicates the probability of observing our statistic or a more extreme statistic from the null hypothesis. Both values agree with the previous results as p values are almost the same. The p-value is also > 0.05 which means the null hypothesis is strong and we fail to reject it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part, you will see that the result you acheived in the previous A/B test can also be acheived by performing regression.<br><br>\n",
    "\n",
    "a. Since each row is either a conversion or no conversion, what type of regression should you be performing in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The goal is to use **statsmodels** to fit the regression model you specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives.  However, you first need to create a column for the intercept, and create a dummy variable column for which page each user received.  Add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()\n",
    "#To remember our dataset columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  \n",
       "0          1        0  \n",
       "1          1        0  \n",
       "2          1        1  \n",
       "3          1        1  \n",
       "4          1        0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['intercept'] = 1 #Addig the intercept column of value equals 1\n",
    "df2[['control', 'ab_page']] = pd.get_dummies(df2['group']) #Getting the dummies to be able to deal with the categorical data\n",
    "df2.drop(labels=['control'], axis=1, inplace=True) \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use **statsmodels** to import your regression model.  Instantiate the model, and fit the model using the two columns you created in part **b.** to predict whether or not an individual converts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df2['converted'], df2[['intercept','ab_page']])\n",
    "results = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Provide the summary of your model below, and use it as necessary to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290585</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290583</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 12 Dec 2020</td> <th>  Pseudo R-squ.:     </th>  <td>8.085e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:00:43</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1897</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.312</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290585\n",
       "Model:                          Logit   Df Residuals:                   290583\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Sat, 12 Dec 2020   Pseudo R-squ.:               8.085e-06\n",
       "Time:                        14:00:43   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1897\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.312      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary() #P-value for the ab_page > 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. What is the p-value associated with **ab_page**? Why does it differ from the value you found in **Part II**?<br><br>  **Hint**: What are the null and alternative hypotheses associated with your regression model, and how do they compare to the null and alternative hypotheses in the **Part II**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**p-value equals 0.190. The p-value differs because of the difference of the difference between the null and alternative hypotheses between part one and part two**\n",
    "\n",
    "**In part two:\n",
    "                                   H0: P new - P old <= 0\n",
    "                                   H1: P new - P old > 0**\n",
    "                                   \n",
    "                                   \n",
    "**In part three:\n",
    "The main null hypothesis of a logistic regression is that there is no association between the response and the term.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now, you are considering other things that might influence whether or not an individual converts.  Discuss why it is a good idea to consider other factors to add into your regression model.  Are there any disadvantages to adding additional terms into your regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other factors like social background and educational background would be a good idea and it would help us understand our model more and how to increase the conversion rate. The disadvantage is that not all the new factors would be useful for predicting and it would lead to difficulties when we create our model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives. You will need to read in the **countries.csv** dataset and merge together your datasets on the approporiate rows.  [Here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html) are the docs for joining tables. \n",
    "\n",
    "Does it appear that country had an impact on conversion?  Don't forget to create dummy variables for these country columns - **Hint: You will need two columns for the three dummy variables.** Provide the statistical output as well as a written response to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = pd.read_csv('./countries.csv')\n",
    "df_new = countries_df.set_index('user_id').join(df2.set_index('user_id'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630000</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-19 06:26:06.548941</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630001</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-16 03:16:42.560309</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630002</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-19 19:20:56.438330</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630003</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-12 10:09:31.510471</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630004</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-18 20:23:58.824994</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "630000       US  2017-01-19 06:26:06.548941  treatment     new_page   \n",
       "630001       US  2017-01-16 03:16:42.560309  treatment     new_page   \n",
       "630002       US  2017-01-19 19:20:56.438330    control     old_page   \n",
       "630003       US  2017-01-12 10:09:31.510471  treatment     new_page   \n",
       "630004       US  2017-01-18 20:23:58.824994  treatment     new_page   \n",
       "\n",
       "         converted  intercept  ab_page  \n",
       "user_id                                 \n",
       "630000           0          1        1  \n",
       "630001           1          1        1  \n",
       "630002           0          1        0  \n",
       "630003           0          1        1  \n",
       "630004           0          1        1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head() #Displaying the new dataset to understand it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203620\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['country'].value_counts() #To know the unique countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630000</th>\n",
       "      <td>2017-01-19 06:26:06.548941</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630001</th>\n",
       "      <td>2017-01-16 03:16:42.560309</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630002</th>\n",
       "      <td>2017-01-19 19:20:56.438330</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630003</th>\n",
       "      <td>2017-01-12 10:09:31.510471</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630004</th>\n",
       "      <td>2017-01-18 20:23:58.824994</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp      group landing_page  converted  \\\n",
       "user_id                                                                  \n",
       "630000   2017-01-19 06:26:06.548941  treatment     new_page          0   \n",
       "630001   2017-01-16 03:16:42.560309  treatment     new_page          1   \n",
       "630002   2017-01-19 19:20:56.438330    control     old_page          0   \n",
       "630003   2017-01-12 10:09:31.510471  treatment     new_page          0   \n",
       "630004   2017-01-18 20:23:58.824994  treatment     new_page          0   \n",
       "\n",
       "         intercept  ab_page  CA  UK  US  \n",
       "user_id                                  \n",
       "630000           1        1   0   0   1  \n",
       "630001           1        1   0   0   1  \n",
       "630002           1        0   0   0   1  \n",
       "630003           1        1   0   0   1  \n",
       "630004           1        1   0   0   1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create the necessary dummy variables\n",
    "df_new[['CA', 'UK', 'US']] = pd.get_dummies(df_new['country'])\n",
    "df_new.drop(labels=['country'], axis=1, inplace=True)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366112\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df_new['converted'], df_new[['intercept','ab_page', 'UK', 'CA']])\n",
    "results = logit_mod.fit()\n",
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290585</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 12 Dec 2020</td> <th>  Pseudo R-squ.:     </th>  <td>2.324e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:00:48</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1758</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.308</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.744</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290585\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Sat, 12 Dec 2020   Pseudo R-squ.:               2.324e-05\n",
       "Time:                        14:00:48   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1758\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "ab_page       -0.0150      0.011     -1.308      0.191      -0.037       0.007\n",
       "UK             0.0099      0.013      0.744      0.457      -0.016       0.036\n",
       "CA            -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtaining the results\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "It is very clear that the P-value > 0.05 which means that the country is not statistically significant and had no impact on conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though you have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion.  Create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "Provide the summary results, and your conclusions based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366108\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "df_new['UK_ab_page'] = df_new['UK']*df_new['ab_page']\n",
    "df_new['CA_ab_page'] = df_new['CA']*df_new['ab_page']\n",
    "logit_mod = sm.Logit(df_new['converted'], df_new[['intercept','ab_page', 'UK', 'CA', 'UK_ab_page', 'CA_ab_page']])\n",
    "results = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290585</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290579</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 12 Dec 2020</td> <th>  Pseudo R-squ.:     </th>  <td>3.483e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:00:51</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1918</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>   -1.9865</td> <td>    0.010</td> <td> -206.344</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>    <td>   -0.0206</td> <td>    0.014</td> <td>   -1.506</td> <td> 0.132</td> <td>   -0.047</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>         <td>   -0.0057</td> <td>    0.019</td> <td>   -0.306</td> <td> 0.760</td> <td>   -0.043</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>         <td>   -0.0175</td> <td>    0.038</td> <td>   -0.465</td> <td> 0.642</td> <td>   -0.091</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_ab_page</th> <td>    0.0314</td> <td>    0.027</td> <td>    1.181</td> <td> 0.238</td> <td>   -0.021</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_ab_page</th> <td>   -0.0469</td> <td>    0.054</td> <td>   -0.872</td> <td> 0.383</td> <td>   -0.152</td> <td>    0.059</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290585\n",
       "Model:                          Logit   Df Residuals:                   290579\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Sat, 12 Dec 2020   Pseudo R-squ.:               3.483e-05\n",
       "Time:                        14:00:51   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1918\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9865      0.010   -206.344      0.000      -2.005      -1.968\n",
       "ab_page       -0.0206      0.014     -1.506      0.132      -0.047       0.006\n",
       "UK            -0.0057      0.019     -0.306      0.760      -0.043       0.031\n",
       "CA            -0.0175      0.038     -0.465      0.642      -0.091       0.056\n",
       "UK_ab_page     0.0314      0.027      1.181      0.238      -0.021       0.084\n",
       "CA_ab_page    -0.0469      0.054     -0.872      0.383      -0.152       0.059\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Interpretation\n",
    " The p-value for the interactions between the page and the country are more than 0.05 ,eg. the p-value for UK_ab_page equals 0.238 and for CA_ab_page equals 0.383, so we can say that both interactions are not statistically significant and has no impact on the conversion rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P-Value in our model > 0.05 which means that both the new page and countries are statistically insignificant factors. We fail to reject the null hypothesis in that case.**\n",
    "\n",
    "**There was no different between the results of regression and the results of our model in part two**\n",
    "\n",
    "**There is no need to use the new page**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
